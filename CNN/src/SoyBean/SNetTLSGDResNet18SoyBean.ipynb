{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "186b4d01",
            "metadata": {},
            "source": [
                "# Paths"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "edb46185",
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset_path = \"../datasets/SimpleSoyBean\"\n",
                "tensorboard_path = \"../logs/\"\n",
                "models_path = \"../models/SoyBean/\""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "096431d1",
            "metadata": {},
            "source": [
                "# Dataloader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d8934365",
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "def my_tensor_image_show ( image , label=None ):\n",
                "    image = image.numpy().transpose((1, 2, 0))\n",
                "    mean = np.array([0.485, 0.456, 0.406])\n",
                "    std = np.array([0.229, 0.224, 0.225])\n",
                "    image = std * image + mean\n",
                "    image = np.clip(image, 0, 1)\n",
                "    plt.imshow(image)\n",
                "    plt.axis('off')\n",
                "    if label is None :\n",
                "        plt.title('Image in tensor format.')\n",
                "    else :\n",
                "        plt.title(f'Image in tensor format | Class: {label:2d}')\n",
                "    plt.show()    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f55b1d08",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from torch.utils.data import Subset\n",
                "\n",
                "# função para dividir o dataset em treino e teste\n",
                "def train_test_dataset(dataset, test_split=0.25):\n",
                "    train_idx, test_idx = train_test_split(list(range(len(dataset))), test_size=test_split)\n",
                "    train_data = Subset(dataset, train_idx)\n",
                "    test_data = Subset(dataset, test_idx)\n",
                "    return train_data, test_data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fd823b2f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# transformações para a ResNet18\n",
                "from torchvision.models import resnet18, ResNet18_Weights\n",
                "my_transform = ResNet18_Weights.IMAGENET1K_V1.transforms()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4bcf81bc",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torchvision\n",
                "\n",
                "# carrega o dataset de imagens com as transformações definidas\n",
                "data = torchvision.datasets.ImageFolder(root=dataset_path, transform=my_transform)\n",
                "\n",
                "# divide o dataset em treino e teste\n",
                "train_data, test_data = train_test_dataset(data, 0.30)\n",
                "\n",
                "batch_size = 512\n",
                "\n",
                "train_tensors = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
                "test_tensors = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n",
                "print(len(data))\n",
                "print(len(train_data))\n",
                "print(len(test_data))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8f5f7c3e",
            "metadata": {},
            "outputs": [],
            "source": [
                "images, labels = next(iter(train_tensors))\n",
                "my_tensor_image_show(images[0], label=labels[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3c024816",
            "metadata": {},
            "outputs": [],
            "source": [
                "images, labels = next(iter(test_tensors))\n",
                "my_tensor_image_show(images[0], label=labels[0])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "6e8962c7",
            "metadata": {},
            "source": [
                "# Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a43f19fe",
            "metadata": {},
            "outputs": [],
            "source": [
                "from torch.utils.tensorboard import SummaryWriter\n",
                "\n",
                "import torch.optim \n",
                "import matplotlib.pyplot as plt\n",
                "  \n",
                "from datetime import datetime\n",
                "\n",
                "from tqdm import tqdm\n",
                "\n",
                "import copy\n",
                "\n",
                "def plot_layers ( net , writer, epoch ) :\n",
                "    layers = list(net.fc.modules())\n",
                "    \n",
                "    layer_id = 1\n",
                "    for layer in layers:\n",
                "        if isinstance(layer, torch.nn.Linear) :\n",
                "\n",
                "#             writer.add_histogram('Bias/conv{}'.format(layer_id), layer.bias, \n",
                "#                                 epoch )\n",
                "            writer.add_histogram('Weight/conv{}'.format(layer_id), layer.weight, \n",
                "                                epoch )\n",
                "#             writer.add_histogram('Grad/conv{}'.format(layer_id), layer.weight.grad, \n",
                "#                                     epoch )\n",
                "            layer_id += 1\n",
                "\n",
                "\n",
                "def train ( train_loader, test_loader, net, dataset_size, my_device='cpu',\n",
                "           prefix=None, upper_bound=100.0, save=False, epochs=100, \n",
                "           lr=1e-1, device='cpu', debug=False, layers2tensorboard=False , batch_size=64) :\n",
                "\n",
                "    # otimizador e função de perda\n",
                "    optimizer = torch.optim.SGD(net.parameters(),lr=lr)\n",
                "    criterion = torch.nn.CrossEntropyLoss()\n",
                "    \n",
                "    now = datetime.now()\n",
                "    suffix = now.strftime(\"%Y%m%d_%H%M%S\")\n",
                "    prefix = suffix if prefix is None else prefix + '-' + suffix  \n",
                "\n",
                "    writer = SummaryWriter( log_dir=tensorboard_path+prefix )\n",
                "        \n",
                "    accuracies = []\n",
                "    max_accuracy = -1.0  \n",
                "\n",
                "    for inputs, labels in train_loader:\n",
                "        print(\"Labels:\", labels.unique())\n",
                "        break\n",
                "\n",
                "\n",
                "    for epoch in tqdm(range(epochs), desc='Training epochs...') :\n",
                "        net.train()\n",
                "        for idx, (train_x, train_label) in enumerate(train_loader):\n",
                "            train_x = train_x.to(device)\n",
                "            train_label = train_label.to(device)\n",
                "\n",
                "            predict_y = net( train_x )\n",
                "            \n",
                "            # loss\n",
                "            error = criterion( predict_y , train_label )\n",
                "\n",
                "            writer.add_scalar( 'Loss/train', error.cpu().item(), \n",
                "                                idx+( epoch*(dataset_size//batch_size) ) )\n",
                "\n",
                "            # backpropagation\n",
                "            optimizer.zero_grad()\n",
                "            error.backward()\n",
                "            optimizer.step()\n",
                "            \n",
                "            # accuracy\n",
                "            predict_ys = torch.max( predict_y, axis=1 )[1]\n",
                "            correct    = torch.sum(predict_ys == train_label)\n",
                "\n",
                "            writer.add_scalar( 'Accuracy/train', correct/train_x.size(0), \n",
                "                                idx+( epoch*(dataset_size//batch_size) ) )\n",
                "\n",
                "            if debug and idx % 10 == 0 :\n",
                "                print( f'idx: {idx:4d}, _error: {error.cpu().item():5.2f}' )\n",
                "\n",
                "        if layers2tensorboard :\n",
                "            plot_layers( net, writer, epoch )\n",
                "\n",
                "        accuracy = validate(net, test_loader, device=device)\n",
                "        accuracies.append(accuracy)\n",
                "        writer.add_scalar( 'Accuracy/test', accuracy, epoch )\n",
                "        \n",
                "        if accuracy > max_accuracy :\n",
                "            best_model = copy.deepcopy(net)\n",
                "            max_accuracy = accuracy\n",
                "            print(\"Saving Best Model with Accuracy: \", accuracy)\n",
                "        \n",
                "        print( f'Epoch: {epoch+1:3d} | Accuracy : {accuracy:7.4f}%' )\n",
                "\n",
                "        if accuracy > upper_bound :\n",
                "            break\n",
                "    \n",
                "    if save : \n",
                "        dataset = \"SoyBean\"\n",
                "        path = f'{models_path}ResNet18-{dataset}-{max_accuracy:.2f}.pkl'\n",
                "        torch.save(best_model, path)\n",
                "        print('Model saved in:',path)\n",
                "    \n",
                "    plt.plot(accuracies)\n",
                "\n",
                "    writer.flush()\n",
                "    writer.close()\n",
                "    \n",
                "    return best_model    "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "af14bae2",
            "metadata": {},
            "source": [
                "# Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7125dc79",
            "metadata": {},
            "outputs": [],
            "source": [
                "# função de validação do modelo\n",
                "def validate ( model , data , device='cpu') :\n",
                "\n",
                "    model.eval()\n",
                "\n",
                "    correct = 0\n",
                "    sum = 0\n",
                "    \n",
                "    for idx, (test_x, test_label) in enumerate(data) : \n",
                "        test_x = test_x.to(device)\n",
                "        test_label = test_label.to(device)\n",
                "        predict_y = model( test_x ).detach()\n",
                "        predict_ys = torch.max( predict_y, axis=1 )[1]\n",
                "        sum = sum + test_x.size(0)\n",
                "        correct = correct + torch.sum(predict_ys == test_label)\n",
                "        correct = correct.cpu().item()\n",
                "    \n",
                "    return correct*100./sum"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "ac13ddce-2738-4924-bc60-b28d1647dc55",
            "metadata": {},
            "source": [
                "# Run"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "05d2f4b2",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from torchvision.models import resnet18\n",
                "\n",
                "# arquivo com modelo treinado no dataset SoyNet\n",
                "path = './models/SoyNet/ResNet18-SoyNet-96.07.pkl'\n",
                "\n",
                "# carrega o modelo\n",
                "modelResNetTL = torch.load(path, weights_only=False)\n",
                "\n",
                "# verifica as camadas\n",
                "for name, param in modelResNetTL.named_parameters():\n",
                "    print(f\"{name}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a7acf4d1-87ab-4671-a60a-172495a1bfc1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# congela as camadas do modelo\n",
                "for param in modelResNetTL.parameters():\n",
                "    param.requires_grad = False\n",
                "\n",
                "# habilita o treinamento da camada final - Transfer Learning\n",
                "modelResNetTL.fc.requires_grad_(True)\n",
                "\n",
                "# define o número de classes do dataset SoyBean\n",
                "num_classes = 13\n",
                "modelResNetTL.fc = torch.nn.Linear(modelResNetTL.fc.in_features, num_classes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4b21e66a-22ee-47c6-aefd-ae5d5866a90d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# verifica as camadas que estão congeladas\n",
                "for name, param in modelResNetTL.named_parameters():\n",
                "    status = \"Trainable\" if param.requires_grad else \"Frozen\"\n",
                "    print(f\"{name}: {status}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f2ce52fc-15ad-4b8e-a298-1936f5731b1c",
            "metadata": {},
            "outputs": [],
            "source": [
                "if torch.cuda.is_available():\n",
                "    my_device = torch.device(\"cuda:0\")\n",
                "else:\n",
                "    my_device = torch.device(\"cpu\")\n",
                "\n",
                "print(f\"Running on {my_device.type}\")\n",
                "    \n",
                "model = modelResNetTL.to(my_device)\n",
                "\n",
                "epochs = 100\n",
                "lr = 1e-3\n",
                "dataset = 'SoyBean'\n",
                "prefix = 'ResNet-TL-{}-e-{}-lr-{}'.format(dataset, epochs, lr)\n",
                "\n",
                "# treina o modelo\n",
                "net = train(train_tensors, test_tensors, model, len(train_data),\n",
                "            epochs=epochs, device=my_device, save=True, \n",
                "            prefix=prefix, lr=lr, layers2tensorboard=True, batch_size=batch_size)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6636167c-5e67-47c2-b89d-355bf01bf1b9",
            "metadata": {},
            "outputs": [],
            "source": [
                "def sample_and_predict ( net, seed=None ) :\n",
                "\n",
                "    if seed is not None :\n",
                "        np.random.seed(seed)\n",
                "\n",
                "    dataset = torchvision.datasets.ImageFolder(root=dataset_path, transform=None)\n",
                "\n",
                "    data = train_test_dataset(dataset, 0.30)[1]\n",
                "    \n",
                "    i = np.random.randint(len(data))\n",
                "    \n",
                "    sample = data[i][0]\n",
                "    plt.figure(figsize=(2,2))\n",
                "    plt.axis('off')\n",
                "    plt.imshow( sample )\n",
                "\n",
                "    print( f'Sample id: {i:3d}' )\n",
                "    \n",
                "    x = my_transform(sample)\n",
                "    print(x.shape)\n",
                "\n",
                "    x = x.unsqueeze_(0)\n",
                "    print(x.shape)\n",
                "\n",
                "    x = x.to(my_device)\n",
                "    \n",
                "    output = net ( x )\n",
                "    predictions = output.squeeze(0).softmax(0)\n",
                "        \n",
                "    predicted_class = torch.argmax(predictions)\n",
                "    predicted_class = predicted_class.data.cpu().item()\n",
                "    \n",
                "    confidence = predictions[predicted_class]\n",
                "    confidence = confidence.data.cpu().item()\n",
                "    \n",
                "    dataset_classes = [\n",
                "        \"bacterial_blight\", \"brown_spot\", \"crestamento\", \"ferrugem\", \"mossaic_virus\", \"powdery_mildew\",\n",
                "        \"septoria\", \"southern_blight\", \"sudden_death_syndrone\", \"yellow_mosaic\"\n",
                "    ]\n",
                "\n",
                "\n",
                "    if predicted_class == data[i][1] : print('Hit')\n",
                "    else: print('Miss')\n",
                "\n",
                "    print(predicted_class)\n",
                "    print( f'Predicted: {dataset_classes[predicted_class]} | Corrected: {dataset_classes[data[i][1]]} | Confidence: {confidence*100:.2f}%'  )\n",
                "    \n",
                "\n",
                "sample_and_predict(net)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
